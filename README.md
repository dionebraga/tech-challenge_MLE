ğŸ“š Tech Challenge - Sistema de Web Scraping + API RESTful

ğŸ“ DescriÃ§Ã£o do Projeto

Este projeto faz parte do Tech Challenge e tem como objetivo a criaÃ§Ã£o de um sistema completo que integra:

Web Scraping: extraÃ§Ã£o de dados de livros do site Books to Scrape
.

Armazenamento Local: persistÃªncia dos dados em arquivos CSV.

API RESTful: implementaÃ§Ã£o em FastAPI, com endpoints documentados em Swagger.

Deploy PÃºblico: aplicaÃ§Ã£o hospedada e acessÃ­vel via Render.

Plano Arquitetural: pipeline pensado para escalabilidade, integraÃ§Ã£o com ML e consumo por cientistas de dados.

ğŸ— Arquitetura do Projeto
tech_challenge/
â”‚
â”œâ”€â”€ tech_challenge_books_api/
â”‚   â”œâ”€â”€ main.py                # Arquivo principal da API
â”‚   â”œâ”€â”€ routers/               # Rotas (Books e Categories)
â”‚   â”œâ”€â”€ schemas/               # Schemas Pydantic
â”‚   â”œâ”€â”€ models/                # Modelos ORM
â”‚   â”œâ”€â”€ repositories/          # Regras de acesso a dados
â”‚   â””â”€â”€ infra/                 # Banco de dados / conexÃµes
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ scraper.py             # Script de Web Scraping
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ books.csv              # Dados extraÃ­dos
â”‚
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ render.yaml                # ConfiguraÃ§Ã£o de deploy no Render
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto

âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o
PrÃ©-requisitos

Python 3.10+

Git

Ambiente virtual (venv) configurado

Passos
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/tech_challenge.git
cd tech_challenge

# Crie e ative o ambiente virtual
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows

# Instale as dependÃªncias
pip install -r requirements.txt

ğŸš€ ExecuÃ§Ã£o Local
Rodar o Web Scraper
python scripts/scraper.py


Isso vai gerar um arquivo data/books.csv com os dados coletados.

Rodar a API Localmente
uvicorn tech_challenge_books_api.main:app --reload


Acesse em: http://127.0.0.1:8000

DocumentaÃ§Ã£o Swagger: http://127.0.0.1:8000/docs

ğŸŒ Deploy PÃºblico

A API estÃ¡ disponÃ­vel em produÃ§Ã£o via Render:

ğŸ”— https://tech-challenge-mle.onrender.com/docs

ğŸ“Œ Endpoints da API
ğŸ“˜ Books

GET /api/v1/books/ â†’ Lista todos os livros

GET /api/v1/books/{id} â†’ Busca livro por ID

POST /api/v1/books/ â†’ Cria novo livro

PATCH /api/v1/books/{id} â†’ Atualiza dados de um livro

DELETE /api/v1/books/{id} â†’ Remove livro

ğŸ“‚ Categories

GET /api/v1/categories/ â†’ Lista todas as categorias

GET /api/v1/categories/{id} â†’ Busca categoria por ID

POST /api/v1/categories/ â†’ Cria nova categoria

PATCH /api/v1/categories/{id} â†’ Atualiza categoria

DELETE /api/v1/categories/{id} â†’ Remove categoria

ğŸ“Š Exemplos de RequisiÃ§Ã£o
Criar Livro
POST /api/v1/books/
Content-Type: application/json

{
  "title": "Clean Code",
  "author": "Robert C. Martin",
  "price": 45.99,
  "category_id": 1
}

Resposta
{
  "id": 1,
  "title": "Clean Code",
  "author": "Robert C. Martin",
  "price": 45.99,
  "category_id": 1
}

ğŸ—‚ Pipeline Arquitetural
flowchart TD
    A[Web Scraping ğŸ“¡] --> B[CSV Storage ğŸ’¾]
    B --> C[FastAPI REST API ğŸš€]
    C --> D[Swagger Docs ğŸ“‘]
    C --> E[Render Deployment â˜ï¸]
    E --> F[Consumo por Cientistas de Dados/ML ğŸ¤–]

ğŸ”® Escalabilidade e Futuro

Banco de Dados: integraÃ§Ã£o futura com PostgreSQL ou MongoDB.

Machine Learning: recomendaÃ§Ãµes de livros baseadas nos dados extraÃ­dos.

CI/CD: pipeline automatizado com GitHub Actions e Render.

âœï¸ Desenvolvido por Dione Braga Ferreira
